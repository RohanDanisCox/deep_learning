{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanDanisCox/deep_learning/blob/master/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVuBfcO_ybzs",
        "colab_type": "text"
      },
      "source": [
        "Test\n",
        "\n",
        "https://fairyonice.github.io/Develop_an_image_captioning_deep_learning_model_using_Flickr_8K_data.htm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgJ-9AXJ3fml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "242e4e06-f0e2-4411-a54d-9dcf839e0e4c"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGP4MzJI2gLR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7c3ef80e-a9e3-4dcc-a618-9e0bf24f6d11"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "import keras\n",
        "import sys, time, os, warnings \n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from collections import Counter \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "print(\"python {}\".format(sys.version))\n",
        "print(\"keras version {}\".format(keras.__version__)); del keras\n",
        "print(\"tensorflow version {}\".format(tf.__version__))\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
        "config.gpu_options.visible_device_list = \"0\"\n",
        "set_session(tf.Session(config=config))\n",
        "\n",
        "def set_seed(sd=123):\n",
        "    from numpy.random import seed\n",
        "    from tensorflow import set_random_seed\n",
        "    import random as rn\n",
        "    ## numpy random seed\n",
        "    seed(sd)\n",
        "    ## core python's random number \n",
        "    rn.seed(sd)\n",
        "    ## tensor flow's random number\n",
        "    set_random_seed(sd)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "python 3.6.7 (default, Oct 22 2018, 11:32:17) \n",
            "[GCC 8.2.0]\n",
            "keras version 2.2.4\n",
            "tensorflow version 1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVY_4oHh5Asf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73fdfb6e-c93f-485a-9d23-6978e6aade98"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0FAdOyfl2qBn",
        "colab": {}
      },
      "source": [
        "## The location of the Flickr8K_ photos\n",
        "dir_Flickr_jpg = \"../Flickr8k/Flicker8k_Dataset/\"\n",
        "## The location of the caption file\n",
        "dir_Flickr_text = \"../Flickr8k/Flickr8k.token.txt\"\n",
        "\n",
        "jpgs = os.listdir(dir_Flickr_jpg)\n",
        "print(\"The number of jpg flies in Flicker8k: {}\".format(len(jpgs)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZYtQT3V2taW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## read in the Flickr caption data\n",
        "file = open(dir_Flickr_text,'r')\n",
        "text = file.read()\n",
        "file.close()\n",
        "\n",
        "\n",
        "datatxt = []\n",
        "for line in text.split('\\n'):\n",
        "    col = line.split('\\t')\n",
        "    if len(col) == 1:\n",
        "        continue\n",
        "    w = col[0].split(\"#\")\n",
        "    datatxt.append(w + [col[1].lower()])\n",
        "\n",
        "df_txt = pd.DataFrame(datatxt,columns=[\"filename\",\"index\",\"caption\"])\n",
        "\n",
        "\n",
        "uni_filenames = np.unique(df_txt.filename.values)\n",
        "print(\"The number of unique file names : {}\".format(len(uni_filenames)))\n",
        "print(\"The distribution of the number of captions for each image:\")\n",
        "Counter(Counter(df_txt.filename.values).values())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwR3m9bz2wGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "npic = 5\n",
        "npix = 224\n",
        "target_size = (npix,npix,3)\n",
        "\n",
        "count = 1\n",
        "fig = plt.figure(figsize=(10,20))\n",
        "for jpgfnm in uni_filenames[:npic]:\n",
        "    filename = dir_Flickr_jpg + '/' + jpgfnm\n",
        "    captions = list(df_txt[\"caption\"].loc[df_txt[\"filename\"]==jpgfnm].values)\n",
        "    image_load = load_img(filename, target_size=target_size)\n",
        "    \n",
        "    ax = fig.add_subplot(npic,2,count,xticks=[],yticks=[])\n",
        "    ax.imshow(image_load)\n",
        "    count += 1\n",
        "    \n",
        "    ax = fig.add_subplot(npic,2,count)\n",
        "    plt.axis('off')\n",
        "    ax.plot()\n",
        "    ax.set_xlim(0,1)\n",
        "    ax.set_ylim(0,len(captions))\n",
        "    for i, caption in enumerate(captions):\n",
        "        ax.text(0,i,caption,fontsize=20)\n",
        "    count += 1\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWn28vga2xJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def df_word(df_txt):\n",
        "    vocabulary = []\n",
        "    for txt in df_txt.caption.values:\n",
        "        vocabulary.extend(txt.split())\n",
        "    print('Vocabulary Size: %d' % len(set(vocabulary)))\n",
        "    ct = Counter(vocabulary)\n",
        "    dfword = pd.DataFrame({\"word\":ct.keys(),\"count\":ct.values()})\n",
        "    dfword = dfword.sort(\"count\",ascending=False)\n",
        "    dfword = dfword.reset_index()[[\"word\",\"count\"]]\n",
        "    return(dfword)\n",
        "dfword = df_word(df_txt)\n",
        "dfword.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SFmsCoU21fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topn = 50\n",
        "\n",
        "def plthist(dfsub, title=\"The top 50 most frequently appearing words\"):\n",
        "    plt.figure(figsize=(20,3))\n",
        "    plt.bar(dfsub.index,dfsub[\"count\"])\n",
        "    plt.yticks(fontsize=20)\n",
        "    plt.xticks(dfsub.index,dfsub[\"word\"],rotation=90,fontsize=20)\n",
        "    plt.title(title,fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "plthist(dfword.iloc[:topn,:],\n",
        "        title=\"The top 50 most frequently appearing words\")\n",
        "plthist(dfword.iloc[-topn:,:],\n",
        "        title=\"The least 50 most frequently appearing words\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rz0FJ1O24g8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "text_original = \"I ate 1000 apples and a banana. I have python v2.7. It's 2:30 pm. Could you buy me iphone7?\"\n",
        "\n",
        "print(text_original)\n",
        "print(\"\\nRemove punctuations..\")\n",
        "def remove_punctuation(text_original):\n",
        "    text_no_punctuation = text_original.translate(None, string.punctuation)\n",
        "    return(text_no_punctuation)\n",
        "text_no_punctuation = remove_punctuation(text_original)\n",
        "print(text_no_punctuation)\n",
        "\n",
        "\n",
        "print(\"\\nRemove a single character word..\")\n",
        "def remove_single_character(text):\n",
        "    text_len_more_than1 = \"\"\n",
        "    for word in text.split():\n",
        "        if len(word) > 1:\n",
        "            text_len_more_than1 += \" \" + word\n",
        "    return(text_len_more_than1)\n",
        "text_len_more_than1 = remove_single_character(text_no_punctuation)\n",
        "print(text_len_more_than1)\n",
        "\n",
        "print(\"\\nRemove words with numeric values..\")\n",
        "def remove_numeric(text,printTF=False):\n",
        "    text_no_numeric = \"\"\n",
        "    for word in text.split():\n",
        "        isalpha = word.isalpha()\n",
        "        if printTF:\n",
        "            print(\"    {:10} : {:}\".format(word,isalpha))\n",
        "        if isalpha:\n",
        "            text_no_numeric += \" \" + word\n",
        "    return(text_no_numeric)\n",
        "text_no_numeric = remove_numeric(text_len_more_than1,printTF=True)\n",
        "print(text_no_numeric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duf5Qcww251D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_clean(text_original):\n",
        "    text = remove_punctuation(text_original)\n",
        "    text = remove_single_character(text)\n",
        "    text = remove_numeric(text)\n",
        "    return(text)\n",
        "\n",
        "\n",
        "for i, caption in enumerate(df_txt.caption.values):\n",
        "    newcaption = text_clean(caption)\n",
        "    df_txt[\"caption\"].iloc[i] = newcaption"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}